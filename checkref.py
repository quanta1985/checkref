import streamlit as st
import re
from docx import Document
from pypdf import PdfReader

# --- C·∫•u h√¨nh trang ---
st.set_page_config(page_title="Smart Reference Check v3", page_icon="üîç", layout="wide")
st.title("üîç Ki·ªÉm tra Tr√≠ch d·∫´n (H·ªó tr·ª£ ƒë·ªãnh d·∫°ng: T√°c gi·∫£ (NƒÉm))")
st.write("Phi√™n b·∫£n c·∫≠p nh·∫≠t: B·∫Øt ƒë∆∞·ª£c c·∫£ 'Nguyen (2020)' v√† '(Nguyen, 2020)'")

# --- 1. H√ÄM ƒê·ªåC FILE (Gi·ªØ nguy√™n, b·ªï sung try-except) ---
def extract_text_from_docx(file):
    try:
        doc = Document(file)
        full_text = []
        for para in doc.paragraphs:
            full_text.append(para.text)
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for para in cell.paragraphs:
                        full_text.append(para.text)
        return "\n".join(full_text)
    except:
        return "ERROR_DOC"

def extract_text_from_pdf(file):
    try:
        reader = PdfReader(file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except:
        return "ERROR_PDF"

# --- 2. H√ÄM T√åM KI·∫æM TR√çCH D·∫™N (N√ÇNG C·∫§P) ---
def find_citations(text):
    citations = []
    
    # Pattern 1: D·∫°ng ƒë√≥ng ngo·∫∑c k√≠n -> (Nguyen, 2020) ho·∫∑c (Nguyen et al., 2020)
    # T√¨m chu·ªói trong ngo·∫∑c, k·∫øt th√∫c b·∫±ng 4 s·ªë
    pattern_closed = r'\(([^)]+?),\s*(\d{4})\)'
    for match in re.finditer(pattern_closed, text):
        name_raw = match.group(1)
        year = match.group(2)
        citations.append({"name": name_raw, "year": year, "full": f"({name_raw}, {year})"})

    # Pattern 2: D·∫°ng m·ªü -> Nguyen (2020) ho·∫∑c Pham Quy Nhan va nnk (2014)
    # Logic: T√¨m m·ªôt chu·ªói Vi·∫øt Hoa (T√™n) ƒë·ª©ng tr∆∞·ªõc (NƒÉm), c√≥ th·ªÉ k·∫πp gi·ªØa b·ªüi 'v√† nnk', 'et al'
    # Regex gi·∫£i th√≠ch:
    # [A-Z√Ä-·ªπ]: B·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ hoa ho·∫∑c ti·∫øng Vi·ªát
    # [A-Za-z√Ä-·ªπ\s]{1,50}?: Theo sau l√† c√°c k√Ω t·ª± ch·ªØ/kho·∫£ng tr·∫Øng, l·∫•y ng·∫Øn nh·∫•t c√≥ th·ªÉ (t·ªëi ƒëa 50 k√Ω t·ª± ƒë·ªÉ tr√°nh b·∫Øt nh·∫ßm c·∫£ c√¢u)
    pattern_open = r'([A-Z√Ä-·ªπ][A-Za-z√Ä-·ªπ\s]{1,50}?)\s*(?:v√† nnk\.?|v√† c·ªông s·ª±|et al\.?)?\s*\(\s*(\d{4})\s*\)'
    
    for match in re.finditer(pattern_open, text):
        name_raw = match.group(1).strip()
        year = match.group(2)
        
        # L·ªçc nhi·ªÖu: T√™n t√°c gi·∫£ th∆∞·ªùng kh√¥ng qu√° d√†i v√† kh√¥ng ch·ª©a t·ª´ l·∫°.
        # N·∫øu "name_raw" ch·ª©a qu√° nhi·ªÅu t·ª´ th∆∞·ªùng (kh√¥ng vi·∫øt hoa), c√≥ th·ªÉ l√† text th∆∞·ªùng.
        # ·ªû ƒë√¢y ta t·∫°m ch·∫•p nh·∫≠n ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c nhi·ªÅu nh·∫•t.
        citations.append({"name": name_raw, "year": year, "full": f"{name_raw} ({year})"})

    # Lo·∫°i b·ªè tr√πng l·∫∑p (Convert list of dicts to unique set based on 'full' string)
    unique_citations = []
    seen = set()
    for c in citations:
        if c['full'] not in seen:
            unique_citations.append(c)
            seen.add(c['full'])
            
    return unique_citations

# --- 3. H√ÄM SO KH·ªöP (FUZZY MATCHING) ---
def check_citation_in_refs(cit_name, cit_year, refs_list):
    # Chu·∫©n h√≥a t√™n t·ª´ tr√≠ch d·∫´n: X√≥a "et al", "v√† nnk", k√Ω t·ª± l·∫°
    clean_name = re.sub(r'(et al\.?|v√† nnk\.?|v√† c·ªông s·ª±|&|and)', '', cit_name, flags=re.IGNORECASE)
    # T√°ch th√†nh c√°c t·ª´ ƒë∆°n: "Tr·∫ßn Th√†nh L√™" -> ['tr·∫ßn', 'th√†nh', 'l√™']
    name_tokens = [t.lower() for t in clean_name.split() if len(t) > 1]
    
    for ref in refs_list:
        if cit_year in ref: # ƒêi·ªÅu ki·ªán 1: Ph·∫£i tr√πng NƒÉm
            ref_lower = ref.lower()
            
            # ƒêi·ªÅu ki·ªán 2: Ki·ªÉm tra t√™n
            # N·∫øu l√† t√™n ti·∫øng Vi·ªát ƒë·∫ßy ƒë·ªß (VD: Tr·∫ßn Th√†nh L√™), ki·ªÉm tra xem chu·ªói ƒë√≥ c√≥ n·∫±m trong ref kh√¥ng
            if clean_name.strip().lower() in ref_lower:
                return True
            
            # N·∫øu kh√¥ng match c·∫£ c·ª•m, ki·ªÉm tra t·ª´ng t·ª´ kh√≥a (D√†nh cho t√™n n∆∞·ªõc ngo√†i: Parlov -> Parlov J.)
            # Logic: N·∫øu t√¨m th·∫•y b·∫•t k·ª≥ token quan tr·ªçng n√†o (nh∆∞ H·ªç) trong Ref
            match_token_count = 0
            for token in name_tokens:
                if token in ref_lower:
                    match_token_count += 1
            
            # N·∫øu t√¨m th·∫•y √≠t nh·∫•t 1 t·ª´ tr√πng kh·ªõp (v·ªõi t√™n ng·∫Øn) ho·∫∑c 2 t·ª´ (v·ªõi t√™n d√†i)
            if match_token_count >= 1: 
                return True
                
    return False

# --- 4. GIAO DI·ªÜN CH√çNH ---
col1, col2 = st.columns([1, 2])
with col1:
    uploaded_file = st.file_uploader("T·∫£i file b√°o c√°o (.docx, .pdf)", type=['docx', 'pdf'])
    if uploaded_file and st.button("Ki·ªÉm tra"):
        st.session_state.processing = True

if uploaded_file and st.session_state.get('processing'):
    # ƒê·ªçc file
    if uploaded_file.name.endswith('.docx'):
        full_text = extract_text_from_docx(uploaded_file)
    else:
        full_text = extract_text_from_pdf(uploaded_file)

    if full_text.startswith("ERROR"):
        st.error("L·ªói ƒë·ªçc file. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng.")
    else:
        # T√°ch Reference v√† Body
        # C·∫£i ti·∫øn: T√¨m t·ª´ kh√≥a Reference cu·ªëi c√πng ƒë·ªÉ tr√°nh nh·∫ßm v·ªõi M·ª•c l·ª•c
        matches = list(re.finditer(r"(t√†i li·ªáu tham kh·∫£o|references)", full_text, re.IGNORECASE))
        
        if not matches:
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m·ª•c 'T√†i li·ªáu tham kh·∫£o'. ƒêang qu√©t to√†n b·ªô file...")
            body_text = full_text
            ref_text = full_text # Qu√©t c·∫£ b√†i n·∫øu kh√¥ng th·∫•y m·ª•c ri√™ng
        else:
            split_idx = matches[-1].end()
            body_text = full_text[:matches[-1].start()]
            ref_text = full_text[split_idx:]

        # X·ª≠ l√Ω Reference List
        ref_lines = [line.strip() for line in ref_text.split('\n') if len(line.strip()) > 10 and re.search(r'\d{4}', line)]
        
        # X·ª≠ l√Ω Citations (D√πng h√†m m·ªõi)
        citations = find_citations(body_text)

        # --- LOGIC CHECK ---
        missing_refs = [] # C√≥ cite nh∆∞ng kh√¥ng c√≥ ref
        
        for cit in citations:
            is_valid = check_citation_in_refs(cit['name'], cit['year'], ref_lines)
            if not is_valid:
                missing_refs.append(cit['full'])

        unused_refs = [] # C√≥ ref nh∆∞ng kh√¥ng ƒë∆∞·ª£c cite
        for ref in ref_lines:
            is_used = False
            # Check ng∆∞·ª£c l·∫°i: Xem ref n√†y c√≥ t·ª´ kh√≥a n√†o xu·∫•t hi·ªán trong danh s√°ch cite kh√¥ng
            # C√°ch n√†y t∆∞∆°ng ƒë·ªëi ph·ª©c t·∫°p, ta d√πng heuristic ƒë∆°n gi·∫£n: Check nƒÉm
            ref_year_match = re.search(r'\d{4}', ref)
            if ref_year_match:
                r_year = ref_year_match.group(0)
                # L·∫•y danh s√°ch cite c√≥ c√πng nƒÉm n√†y
                same_year_cites = [c for c in citations if c['year'] == r_year]
                
                if not same_year_cites:
                    unused_refs.append(ref) # Kh√¥ng c√≥ cite n√†o d√πng nƒÉm n√†y -> Ch·∫Øc ch·∫Øn th·ª´a
                else:
                    # C√≥ cite c√πng nƒÉm -> Ki·ªÉm tra t√™n
                    # N·∫øu t√™n trong Ref xu·∫•t hi·ªán trong t√™n c·ªßa Cite (ho·∫∑c ng∆∞·ª£c l·∫°i)
                    match_found = False
                    for c in same_year_cites:
                        # Clean t√™n cite
                        c_name_clean = re.sub(r'(et al|v√† nnk|&).*', '', c['name'], flags=re.IGNORECASE).strip()
                        # T√°ch t√™n Ref (th∆∞·ªùng l√† ƒëo·∫°n ƒë·∫ßu tr∆∞·ªõc nƒÉm)
                        ref_start = ref.split(r_year)[0].lower()
                        
                        # So s√°nh fuzzy
                        tokens = c_name_clean.lower().split()
                        for t in tokens:
                            if len(t) > 2 and t in ref_start:
                                match_found = True
                                break
                        if match_found: break
                    
                    if not match_found:
                        unused_refs.append(ref)

        # --- HI·ªÇN TH·ªä ---
        st.divider()
        m1, m2 = st.columns(2)
        m1.metric("S·ªë tr√≠ch d·∫´n t√¨m th·∫•y", len(citations))
        m2.metric("S·ªë t√†i li·ªáu tham kh·∫£o", len(ref_lines))
        st.divider()

        c1, c2 = st.columns(2)
        with c1:
            st.subheader("‚ùå Tr√≠ch d·∫´n thi·∫øu trong danh m·ª•c")
            if missing_refs:
                for item in missing_refs:
                    st.error(item)
            else:
                st.success("T·∫•t c·∫£ tr√≠ch d·∫´n ƒë·ªÅu c√≥ ngu·ªìn!")

        with c2:
            st.subheader("‚ö†Ô∏è T√†i li·ªáu th·ª´a (C√≥ th·ªÉ ch∆∞a cite)")
            if unused_refs:
                for item in unused_refs:
                    st.warning(item)
                    st.caption("---")
            else:
                st.success("Danh m·ª•c t√†i li·ªáu g·ªçn g√†ng!")
