import streamlit as st
import re
import time
from docx import Document
from pypdf import PdfReader

# --- C·∫§U H√åNH GIAO DI·ªÜN ---
st.set_page_config(
    page_title="Citation Pro Checker v5",
    page_icon="‚úÖ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS ---
st.markdown("""
<style>
    .big-font { font-size:20px !important; font-weight: bold; }
    .success-box { padding:15px; border-radius:10px; background-color:#d4edda; color:#155724; border: 1px solid #c3e6cb; }
    .error-box { padding:15px; border-radius:10px; background-color:#f8d7da; color:#721c24; border: 1px solid #f5c6cb; }
    .warning-box { padding:15px; border-radius:10px; background-color:#fff3cd; color:#856404; border: 1px solid #ffeeba; }
</style>
""", unsafe_allow_html=True)

# --- 1. H√ÄM ƒê·ªåC FILE ---
def extract_text_from_docx(file):
    try:
        doc = Document(file)
        full_text = []
        for para in doc.paragraphs:
            full_text.append(para.text)
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for para in cell.paragraphs:
                        full_text.append(para.text)
        return "\n".join(full_text)
    except:
        return "ERROR_DOC"

def extract_text_from_pdf(file):
    try:
        reader = PdfReader(file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except:
        return "ERROR_PDF"

# --- 2. H√ÄM T√åM TR√çCH D·∫™N (N√ÇNG C·∫§P X·ª¨ L√ù D·∫§U CH·∫§M PH·∫®Y) ---
def find_citations_v5(text):
    citations = []
    
    # --- A. X·ª≠ l√Ω d·∫°ng trong ngo·∫∑c: (Name, Year; Name, Year) ---
    # B∆∞·ªõc 1: T√¨m t·∫•t c·∫£ c√°c c·ª•m trong ngo·∫∑c ƒë∆°n c√≥ ch·ª©a √≠t nh·∫•t 1 nƒÉm (4 s·ªë)
    # Regex n√†y b·∫Øt n·ªôi dung trong ngo·∫∑c (...)
    parenthetical_pattern = r'\(([^)]*?\d{4}[^)]*?)\)'
    
    for match in re.finditer(parenthetical_pattern, text):
        content = match.group(1)
        
        # B∆∞·ªõc 2: T√°ch theo d·∫•u ch·∫•m ph·∫©y (cho tr∆∞·ªùng h·ª£p tr√≠ch d·∫´n g·ªôp)
        # VD: "Lee & Pradhan, 2007; Crawford et al., 2021" -> T√°ch l√†m 2
        parts = content.split(';')
        
        for part in parts:
            part = part.strip()
            # B∆∞·ªõc 3: Trong m·ªói ph·∫ßn nh·ªè, t√¨m c·∫∑p Name - Year
            # T√¨m 4 s·ªë cu·ªëi c√πng l√†m NƒÉm
            year_match = re.search(r'(\d{4})[a-z]?', part) 
            if year_match:
                year = year_match.group(1)
                # T√™n l√† ph·∫ßn ƒë·ª©ng tr∆∞·ªõc nƒÉm (b·ªè d·∫•u ph·∫©y th·ª´a)
                # VD: "Lee & Pradhan, 2007" -> Name: "Lee & Pradhan"
                name_part = part[:year_match.start()].strip().rstrip(',').strip()
                
                if len(name_part) > 1: # Tr√°nh r√°c
                    citations.append({"name": name_part, "year": year, "full": f"({name_part}, {year})"})

    # --- B. X·ª≠ l√Ω d·∫°ng m·ªü: Name (Year) ---
    # VD: Parlov v√† nnk (2019)
    pattern_open = r'([A-Z√Ä-·ªπ][A-Za-z√Ä-·ªπ\s&.]{1,50}?)\s*\(\s*(\d{4})\s*\)'
    for match in re.finditer(pattern_open, text):
        name_raw = match.group(1).strip()
        year = match.group(2)
        # Lo·∫°i b·ªè c√°c t·ª´ n·ªëi cu·ªëi c√πng n·∫øu d√≠nh (VD: "ABC et al" -> "ABC")
        citations.append({"name": name_raw, "year": year, "full": f"{name_raw} ({year})"})

    # L·ªçc tr√πng
    unique_citations = []
    seen = set()
    for c in citations:
        key = f"{c['name']}_{c['year']}"
        if key not in seen:
            unique_citations.append(c)
            seen.add(key)
            
    return unique_citations

# --- 3. H√ÄM SO KH·ªöP (N√ÇNG C·∫§P T·ª™ ƒêI·ªÇN VN) ---
def check_citation_in_refs(cit_name, cit_year, refs_list):
    # Chu·∫©n h√≥a t√™n: X√≥a t·∫•t c·∫£ c√°c t·ª´ n·ªëi nhi·ªÖu
    # Th√™m "& cs" (c·ªông s·ª±), "cs", "v√† nnk"
    stopwords_regex = r'(et al\.?|v√† nnk\.?|v√† c·ªông s·ª±|& cs\.?|&|and|,\s*cs)'
    
    clean_cit_name = re.sub(stopwords_regex, ' ', cit_name, flags=re.IGNORECASE).strip()
    
    # T√°ch t√™n th√†nh c√°c t·ª´ kh√≥a (tokens)
    # VD: "Tr·∫ßn VƒÉn T·ªõ" -> ['tr·∫ßn', 'vƒÉn', 't·ªõ']
    cit_tokens = [t.lower() for t in clean_cit_name.split() if len(t) > 1]
    
    for ref in refs_list:
        # ƒêi·ªÅu ki·ªán 1: Ph·∫£i ch·ª©a NƒÉm
        if cit_year in ref:
            ref_lower = ref.lower()
            
            # ƒêi·ªÅu ki·ªán 2: Ki·ªÉm tra t√™n (Fuzzy Matching)
            
            # Case A: T√™n Cite n·∫±m tr·ªçn trong Ref (D√†nh cho t√™n ti·∫øng Vi·ªát ƒë·∫ßy ƒë·ªß)
            if clean_cit_name.lower() in ref_lower:
                return True
                
            # Case B: So kh·ªõp t·ª´ng t·ª´ (D√†nh cho t√™n n∆∞·ªõc ngo√†i ho·∫∑c t√™n vi·∫øt t·∫Øt)
            # VD: Cite="H√†", Ref="H√†, T. T." -> Kh·ªõp token "h√†"
            match_token_count = 0
            for token in cit_tokens:
                # Token ph·∫£i xu·∫•t hi·ªán TR∆Ø·ªöC ph·∫ßn nƒÉm trong Ref (ƒë·ªÉ tr√°nh tr√πng v·ªõi t√™n b√†i b√°o)
                # Tuy nhi√™n ƒë·ªÉ ƒë∆°n gi·∫£n v√† hi·ªáu qu·∫£, ta check trong c·∫£ string Ref tr∆∞·ªõc
                if token in ref_lower:
                    match_token_count += 1
            
            # N·∫øu t√™n ng·∫Øn (1 t·ª´) -> Ph·∫£i kh·ªõp 1 t·ª´
            # N·∫øu t√™n d√†i (>1 t·ª´) -> Ph·∫£i kh·ªõp √≠t nh·∫•t 1 t·ª´ (ch·∫•p nh·∫≠n vi·∫øt t·∫Øt)
            if len(cit_tokens) > 0 and match_token_count >= 1:
                return True
                
    return False

# --- 4. GIAO DI·ªÜN ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2921/2921226.png", width=80)
    st.title("Citation Pro v5")
    st.write("Phi√™n b·∫£n s·ª≠a l·ªói tr√≠ch d·∫´n g·ªôp (;)")
    uploaded_file = st.file_uploader("üìÇ T·∫£i file b√°o c√°o:", type=['docx', 'pdf'])

st.title("üìë Ki·ªÉm tra T√†i li·ªáu (Fix d·∫•u ; v√† & cs)")

if uploaded_file:
    if st.button("üöÄ B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch", type="primary"):
        with st.status("ƒêang x·ª≠ l√Ω...", expanded=True) as status:
            time.sleep(0.5)
            
            # ƒê·ªçc file
            if uploaded_file.name.endswith('.docx'):
                full_text = extract_text_from_docx(uploaded_file)
            else:
                full_text = extract_text_from_pdf(uploaded_file)
            
            if full_text.startswith("ERROR"):
                st.error("L·ªói ƒë·ªçc file.")
                st.stop()

            # T√°ch References
            matches = list(re.finditer(r"(t√†i li·ªáu tham kh·∫£o|references)", full_text, re.IGNORECASE))
            if not matches:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m·ª•c 'T√†i li·ªáu tham kh·∫£o'. ƒêang qu√©t to√†n b·ªô file.")
                ref_text = full_text
                body_text = full_text
            else:
                split_idx = matches[-1].end()
                body_text = full_text[:matches[-1].start()]
                ref_text = full_text[split_idx:]
            
            # X·ª≠ l√Ω d·ªØ li·ªáu
            ref_lines = [line.strip() for line in ref_text.split('\n') if len(line.strip()) > 10 and re.search(r'\d{4}', line)]
            citations = find_citations_v5(body_text) # D√πng h√†m v5 m·ªõi

            # Logic Check
            missing_refs = []
            for cit in citations:
                if not check_citation_in_refs(cit['name'], cit['year'], ref_lines):
                    missing_refs.append(cit['full'])

            unused_refs = []
            for ref in ref_lines:
                # L·∫•y nƒÉm c·ªßa Ref
                ref_year_match = re.search(r'\d{4}', ref)
                if ref_year_match:
                    r_year = ref_year_match.group(0)
                    
                    # T√¨m xem c√≥ Cite n√†o c√πng nƒÉm kh√¥ng
                    same_year_cites = [c for c in citations if c['year'] == r_year]
                    
                    is_found = False
                    if same_year_cites:
                        for c in same_year_cites:
                            if check_citation_in_refs(c['name'], c['year'], [ref]):
                                is_found = True
                                break
                    
                    if not is_found:
                        unused_refs.append(ref)
            
            status.update(label="‚úÖ Ho√†n t·∫•t!", state="complete", expanded=False)

        # K·∫øt qu·∫£
        st.divider()
        c1, c2, c3 = st.columns(3)
        c1.metric("Citation (In-text)", len(citations))
        c2.metric("Reference List", len(ref_lines))
        
        err_num = len(missing_refs) + len(unused_refs)
        c3.metric("S·ªë l∆∞·ª£ng c·∫£nh b√°o", err_num, delta_color="inverse")

        st.divider()
        t1, t2 = st.tabs(["üî¥ THI·∫æU REF (Missing)", "üü° TH·ª™A REF (Unused)"])
        
        with t1:
            if missing_refs:
                for i in missing_refs: st.error(i)
            else:
                st.success("Kh√¥ng c√≥ tr√≠ch d·∫´n n√†o b·ªã thi·∫øu!")
        
        with t2:
            if unused_refs:
                for i in unused_refs: st.warning(i)
            else:
                st.success("Danh m·ª•c t√†i li·ªáu ho√†n to√†n kh·ªõp!")
