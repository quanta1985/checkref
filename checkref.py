import streamlit as st
import re
import time
import pandas as pd
from docx import Document
from pypdf import PdfReader
from thefuzz import fuzz # Th∆∞ vi·ªán AI

# --- 1. C·∫§U H√åNH & CSS (GI·ªÆ NGUY√äN 100%) ---
st.set_page_config(
    page_title="Citation Pro | AI Fuzzy Logic",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    /* Font v√† m√†u n·ªÅn t·ªïng th·ªÉ */
    .stApp { background-color: #f8f9fa; }
    
    /* Style cho c√°c Card (Kh·ªëi) */
    .css-card {
        border-radius: 15px; padding: 20px; background-color: white;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05); margin-bottom: 20px; border: 1px solid #e9ecef;
    }
    
    /* Header ch√≠nh */
    .main-header { font-family: 'Helvetica Neue', sans-serif; color: #0d6efd; text-align: center; margin-bottom: 30px; }
    
    /* Metric Box */
    div[data-testid="stMetric"] {
        background-color: #ffffff; border: 1px solid #e0e0e0; padding: 15px;
        border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); text-align: center;
    }
    
    /* Alert Boxes */
    .alert-error { padding: 12px; border-radius: 8px; background-color: #fff5f5; border-left: 5px solid #fc8181; color: #c53030; margin-bottom: 10px; font-size: 15px; }
    .alert-warning { padding: 12px; border-radius: 8px; background-color: #fffaf0; border-left: 5px solid #f6ad55; color: #c05621; margin-bottom: 10px; font-size: 15px; }
    .alert-success { padding: 12px; border-radius: 8px; background-color: #f0fff4; border-left: 5px solid #48bb78; color: #2f855a; font-weight: bold; }
    .beta-note { font-size: 13px; color: #6c757d; font-style: italic; text-align: center; margin-bottom: 20px; }
</style>
""", unsafe_allow_html=True)

# --- 2. C√ÅC H√ÄM X·ª¨ L√ù (LOGIC ƒê√É N√ÇNG C·∫§P v10) ---

def extract_text_from_docx(file):
    try:
        doc = Document(file)
        full_text = []
        for para in doc.paragraphs: full_text.append(para.text)
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for para in cell.paragraphs: full_text.append(para.text)
        return "\n".join(full_text)
    except: return "ERROR_DOC"

def extract_text_from_pdf(file):
    try:
        reader = PdfReader(file)
        text = ""
        for page in reader.pages: text += page.extract_text() + "\n"
        return text
    except: return "ERROR_PDF"

def preprocess_text(text):
    # N·ªëi t·ª´ b·ªã ng·∫Øt d√≤ng v√† l√†m s·∫°ch
    text = re.sub(r'-\s*\n\s*', '', text)
    text = text.replace('\n', ' ').replace('\r', ' ')
    text = re.sub(r'\s+', ' ', text)
    return text

def is_legal_or_standard(text):
    text_lower = text.lower()
    keywords = [
        'tcvn', 'qcvn', 'iso', 'lu·∫≠t', 'ngh·ªã ƒë·ªãnh', 'quy·∫øt ƒë·ªãnh', 'th√¥ng t∆∞', 
        'ch·ªâ th·ªã', 'qƒë-ttg', 'nd-cp', 'tt-btnmt', 'luat', 'nghi dinh', 
        'quyet dinh', 'thong tu', 'ti√™u chu·∫©n', 'quy chu·∫©n', 'ch√≠nh ph·ªß', 
        'qu·ªëc h·ªôi', 'b·ªô t√†i nguy√™n', 'b·ªô x√¢y d·ª±ng', 'b·ªô khoa h·ªçc'
    ]
    for kw in keywords:
        if kw in text_lower: return True
    return False

# --- H√ÄM CHECK T·ª™ KH√ìA R√ÅC (BLACKLIST) ---
def is_garbage(text):
    text_lower = text.lower()
    # Danh s√°ch t·ª´ kh√≥a c·∫•m xu·∫•t hi·ªán trong T√™n T√°c Gi·∫£
    blacklist = [
        'th√°ng', 'ng√†y', 'nƒÉm', 'l√∫c', 'tr∆∞·ªõc', 'sau', 'kho·∫£ng', 'h√¨nh', 'b·∫£ng', 'bi·ªÉu', 
        's∆° ƒë·ªì', 'ph∆∞∆°ng tr√¨nh', 'c√¥ng th·ª©c', 'h·ªá s·ªë', 'gi√° tr·ªã', 't·ªâ l·ªá', 'k·∫øt qu·∫£', 
        'ƒëo·∫°n', 'ph·∫ßn', 'm·ª•c', 'b·∫£n ƒë·ªì', 'giai ƒëo·∫°n', 's·ªë', 'nghi√™n c·ª©u', 'ph√¢n t√≠ch', 
        'ƒë√°nh gi√°', 'ƒë·ªëi v·ªõi', 'c·ªßa', 'b·ªüi', 'ƒë∆∞·ª£c', 'trong', 't·∫°i'
    ]
    
    # Check 1: Ch·ª©a t·ª´ kh√≥a c·∫•m
    for word in blacklist:
        # D√πng regex ƒë·ªÉ b·∫Øt ch√≠nh x√°c t·ª´ (tr√°nh b·∫Øt nh·∫ßm ch·ªØ 'th·∫Øng' ch·ª©a 'th√°ng')
        if re.search(r'\b' + re.escape(word) + r'\b', text_lower):
            return True
            
    # Check 2: Ch·ª©a k√Ω t·ª± to√°n h·ªçc
    invalid_chars = ['/', '=', '>', '<', '%', '+', '\\']
    for char in invalid_chars:
        if char in text: return True
        
    return False

def check_citation_fuzzy(cit_name, cit_year, refs_list, threshold=80):
    if is_legal_or_standard(cit_name): return True

    # CLEANER M·∫†NH H∆†N: X·ª≠ l√Ω b·∫•t ch·∫•p c√°c ki·ªÉu vi·∫øt t·∫Øt, th·ª´a d·∫•u c√°ch
    # Regex n√†y b·∫Øt: "et al", "et. al", "v√† c·ªông s·ª±", "v√†  c·ªông s·ª±", "& cs", "&cs"
    clean_cit = re.sub(r'(et\s*al\.?|v√†\s*nnk\.?|v√†\s*c·ªông\s*s·ª±|&\s*cs\.?|&|and)', ' ', cit_name, flags=re.IGNORECASE).strip()
    
    # Lo·∫°i b·ªè c√°c t·ª´ n·ªëi th·ª´a ·ªü ƒë·∫ßu c√¢u (n·∫øu l·ª° b·ªã d√≠nh)
    clean_cit = re.sub(r'^(ƒë∆∞·ª£c|b·ªüi|c·ªßa|theo)\s+', '', clean_cit, flags=re.IGNORECASE).strip()
    
    for ref in refs_list:
        if str(cit_year) in ref:
            # D√πng token_set_ratio: C·ª±c t·ªët cho vi·ªác so s√°nh chu·ªói con
            # VD: "Hobbins" so v·ªõi "Hobbins, M. et al." -> Score 100
            score = fuzz.token_set_ratio(clean_cit, ref)
            if score >= threshold:
                return True
    return False

def find_citations_v10(text):
    citations = []
    
    # --- Pattern 1: Trong ngo·∫∑c (...) ---
    for match in re.finditer(r'\(([^)]*?\d{4}[^)]*?)\)', text):
        content = match.group(1)
        for part in content.split(';'):
            part = part.strip()
            year_match = re.search(r'(\d{4})[a-z]?', part) 
            if year_match:
                year = year_match.group(1)
                name_part = part[:year_match.start()].strip().rstrip(',:').strip()
                
                # √Åp d·ª•ng b·ªô l·ªçc
                if len(name_part) > 1 and len(name_part) < 100 and not is_legal_or_standard(name_part):
                     if not is_garbage(name_part):
                        citations.append({"name": name_part, "year": year, "full": f"({name_part}, {year})"})

    # --- Pattern 2: D·∫°ng m·ªü Name (Year) ---
    # FIX QUAN TR·ªåNG: Lo·∫°i b·ªè d·∫•u ch·∫•m '.' kh·ªèi regex t√™n t√°c gi·∫£ ƒë·ªÉ tr√°nh ƒÉn lan sang c√¢u tr∆∞·ªõc
    # C≈©: [A-Za-z√Ä-·ªπ\s&.\-] -> M·ªõi: [A-Za-z√Ä-·ªπ\s&\-] (B·ªè d·∫•u ch·∫•m)
    for match in re.finditer(r'([A-Z√Ä-·ªπ][A-Za-z√Ä-·ªπ\s&\-]{1,60}?)\s*\(\s*(\d{4})\s*\)', text):
        raw_name = match.group(1).strip()
        year = match.group(2)
        
        # √Åp d·ª•ng b·ªô l·ªçc
        if not is_legal_or_standard(raw_name) and not is_garbage(raw_name):
             citations.append({"name": raw_name, "year": year, "full": f"{raw_name} ({year})"})

    # Unique
    unique_citations = []
    seen = set()
    for c in citations:
        key = f"{c['name']}_{c['year']}"
        if key not in seen:
            unique_citations.append(c)
            seen.add(key)
    return unique_citations

# --- 3. GIAO DI·ªÜN CH√çNH (GI·ªÆ NGUY√äN) ---

# --- SIDEBAR ---
with st.sidebar:
    st.markdown("<h2 style='text-align: center; color: #0d6efd;'>üéì Citation Pro <br><span style='font-size:16px; color: #666;'>(AI FUZZY CHECK )</span></h2>", unsafe_allow_html=True)
    st.markdown("---")
    uploaded_file = st.file_uploader("üìÇ **T·∫£i b√°o c√°o l√™n ƒë√¢y**:", type=['docx', 'pdf'])
    
    st.markdown("---")
    with st.expander("‚ÑπÔ∏è H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"):
        st.markdown("""
        1. Upload file b√°o c√°o (.docx/.pdf).
        2. Ch·ªù h·ªá th·ªëng t·ª± ƒë·ªông qu√©t.
        3. Xem k·∫øt qu·∫£ t·∫°i Dashboard b√™n ph·∫£i.
        """)
    
    st.info("‚ö†Ô∏è **L∆∞u √Ω:** App ƒëang trong qu√° tr√¨nh ph√°t tri·ªÉn (Beta). K·∫øt qu·∫£ ki·ªÉm tra ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o nhanh.")
    st.caption("Dev by Quan HUMG")

# --- MAIN PAGE ---
if not uploaded_file:
    st.markdown("<div style='text-align: center; padding: 50px;'>", unsafe_allow_html=True)
    st.title("C√¥ng c·ª• R√† so√°t Tr√≠ch d·∫´n & T√†i li·ªáu tham kh·∫£o")
    st.markdown("### üöÄ Nhanh ch√≥ng - (G·∫ßn) Ch√≠nh x√°c - (S·∫Øp) Chuy√™n nghi·ªáp - V√† JUST FOR FUN üòé")
    st.markdown("Ki·ªÉm tra s·ª± ƒë·ªìng b·ªô gi·ªØa *Tr√≠ch d·∫´n trong b√†i (In-text)* v√† *Danh m·ª•c tham kh·∫£o (References)*.")
    st.image("https://cdn-icons-png.flaticon.com/512/8662/8662266.png", width=150)
    st.info("üëà Vui l√≤ng t·∫£i file b√°o c√°o ·ªü thanh b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.markdown("</div>", unsafe_allow_html=True)

else:
    # --- X·ª¨ L√ù D·ªÆ LI·ªÜU ---
    with st.container():
        with st.status("ƒêang ph√¢n t√≠ch d·ªØ li·ªáu...", expanded=True) as status:
            time.sleep(0.3)
            st.write("üìÑ ƒêang ƒë·ªçc v√† l√†m s·∫°ch file...")
            
            if uploaded_file.name.endswith('.docx'):
                raw_text = extract_text_from_docx(uploaded_file)
            else:
                raw_text = extract_text_from_pdf(uploaded_file)
            
            if raw_text.startswith("ERROR"):
                status.update(label="‚ùå L·ªói ƒë·ªçc file!", state="error")
                st.stop()

            st.write("üîç ƒêang t√°ch danh m·ª•c v√† tr√≠ch d·∫´n...")
            matches = list(re.finditer(r"(t√†i li·ªáu tham kh·∫£o|references)", raw_text, re.IGNORECASE))
            if not matches:
                ref_raw = raw_text
                body_raw = raw_text
                st.toast("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ti√™u ƒë·ªÅ References, qu√©t to√†n b·ªô.", icon="‚ö†Ô∏è")
            else:
                split_idx = matches[-1].end()
                body_raw = raw_text[:matches[-1].start()]
                ref_raw = raw_text[split_idx:]
            
            body_text = preprocess_text(body_raw)
            ref_lines = [line.strip() for line in ref_raw.split('\n') if len(line.strip()) > 10 and re.search(r'\d{4}', line)]

            st.write("üß† ƒêang ch·∫°y thu·∫≠t to√°n AI Fuzzy Matching...")
            citations = find_citations_v10(body_text)

            # --- LOGIC CHECK (FUZZY) ---
            missing_refs = []
            for cit in citations:
                if not check_citation_fuzzy(cit['name'], cit['year'], ref_lines):
                    missing_refs.append(cit['full'])

            unused_refs = []
            for ref in ref_lines:
                if is_legal_or_standard(ref): continue
                
                ref_year_match = re.search(r'\d{4}', ref)
                if ref_year_match:
                    r_year = ref_year_match.group(0)
                    same_year_cites = [c for c in citations if c['year'] == r_year]
                    
                    is_found = False
                    if same_year_cites:
                        for c in same_year_cites:
                            if check_citation_fuzzy(c['name'], c['year'], [ref]):
                                is_found = True
                                break
                    if not is_found:
                        unused_refs.append(ref)
            
            status.update(label="‚úÖ ƒê√£ ph√¢n t√≠ch xong!", state="complete", expanded=False)

    # --- DASHBOARD K·∫æT QU·∫¢ ---
    
    st.markdown("<h3 style='margin-top: 20px;'>üìä T·ªïng quan (Dashboard)</h3>", unsafe_allow_html=True)
    
    st.markdown("""
    <div style="background-color: #ffe6e6; border: 1px solid #ffcccc; padding: 10px; border-radius: 5px; color: #cc0000; margin-bottom: 15px; font-size: 14px;">
        <b>‚ö†Ô∏è L∆ØU √ù:</b> Nh·ªØng tr√≠ch d·∫´n b·ªã xu·ªëng d√≤ng trong b·∫£n th·∫£o (v√≠ d·ª• <i>Rasmussen</i> th√†nh <i>Ras-mussen</i>) c√≥ th·ªÉ b·ªã b√°o l·ªói thi·∫øu tr√≠ch d·∫´n do h·∫°n ch·∫ø c·ªßa vi·ªác tr√≠ch xu·∫•t vƒÉn b·∫£n PDF. Vui l√≤ng ki·ªÉm tra l·∫°i th·ªß c√¥ng.
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('<p class="beta-note">(*) K·∫øt qu·∫£ d·ª±a tr√™n AI Fuzzy Logic. Vui l√≤ng ki·ªÉm tra l·∫°i th·ªß c√¥ng c√°c m·ª•c b√°o l·ªói.</p>', unsafe_allow_html=True)
    
    # Metrics
    m1, m2, m3, m4 = st.columns(4)
    with m1: st.metric("T·ªïng tr√≠ch d·∫´n", len(citations), border=True)
    with m2: st.metric("Danh m·ª•c Ref", len(ref_lines), border=True)
    
    err_missing = len(missing_refs)
    err_unused = len(unused_refs)
    
    with m3: 
        st.metric("L·ªói thi·∫øu Ref", err_missing, delta="-{}".format(err_missing) if err_missing > 0 else "OK", delta_color="inverse", border=True)
    with m4:
        st.metric("L·ªói th·ª´a Ref", err_unused, delta="-{}".format(err_unused) if err_unused > 0 else "OK", delta_color="inverse", border=True)

    st.write("") 

    # Tabs
    tab_miss, tab_unused, tab_data = st.tabs(["üö´ TR√çCH D·∫™N THI·∫æU (Missing)", "‚ö†Ô∏è DANH M·ª§C TH·ª™A (Unused)", "üìã D·ªÆ LI·ªÜU CHI TI·∫æT"])

    with tab_miss:
        st.markdown(f"**Danh s√°ch {len(missing_refs)} tr√≠ch d·∫´n c√≥ trong b√†i nh∆∞ng kh√¥ng t√¨m th·∫•y trong danh m·ª•c:**")
        if missing_refs:
            for item in missing_refs:
                st.markdown(f'<div class="alert-error">‚ùå <b>{item}</b> - <i>Kh√¥ng t√¨m th·∫•y ngu·ªìn</i></div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="alert-success">üéâ Tuy·ªát v·ªùi! Kh√¥ng c√≥ tr√≠ch d·∫´n n√†o b·ªã thi·∫øu.</div>', unsafe_allow_html=True)

    with tab_unused:
        st.markdown(f"**Danh s√°ch {len(unused_refs)} t√†i li·ªáu c√≥ trong danh m·ª•c nh∆∞ng ch∆∞a ƒë∆∞·ª£c tr√≠ch d·∫´n:**")
        if unused_refs:
            for item in unused_refs:
                st.markdown(f'<div class="alert-warning">‚ö†Ô∏è {item}</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="alert-success">üéâ Danh m·ª•c t√†i li·ªáu r·∫•t g·ªçn g√†ng.</div>', unsafe_allow_html=True)

    with tab_data:
        st.markdown("#### Tra c·ª©u d·ªØ li·ªáu g·ªëc")
        col_d1, col_d2 = st.columns(2)
        
        with col_d1:
            st.caption("D·ªØ li·ªáu Tr√≠ch d·∫´n (In-text)")
            if citations:
                df_cit = pd.DataFrame(citations)
                st.dataframe(df_cit, use_container_width=True, hide_index=True)
            else: st.info("Kh√¥ng c√≥ d·ªØ li·ªáu")

        with col_d2:
            st.caption("D·ªØ li·ªáu Danh m·ª•c (References)")
            if ref_lines:
                df_ref = pd.DataFrame(ref_lines, columns=["N·ªôi dung tham kh·∫£o"])
                st.dataframe(df_ref, use_container_width=True, hide_index=True)
            else: st.info("Kh√¥ng c√≥ d·ªØ li·ªáu")
