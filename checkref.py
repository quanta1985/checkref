import streamlit as st
import re
import time
import pandas as pd
from docx import Document
from pypdf import PdfReader
from thefuzz import fuzz # <--- Th∆∞ vi·ªán m·ªõi: Tr√°i tim c·ªßa thu·∫≠t to√°n

# --- 1. C·∫§U H√åNH & CSS (GI·ªÆ NGUY√äN) ---
st.set_page_config(
    page_title="Citation Pro | Fuzzy Check",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .stApp { background-color: #f8f9fa; }
    .css-card { border-radius: 15px; padding: 20px; background-color: white; box-shadow: 0 4px 6px rgba(0,0,0,0.05); margin-bottom: 20px; border: 1px solid #e9ecef; }
    .alert-error { padding: 12px; border-radius: 8px; background-color: #fff5f5; border-left: 5px solid #fc8181; color: #c53030; margin-bottom: 10px; font-size: 15px; }
    .alert-warning { padding: 12px; border-radius: 8px; background-color: #fffaf0; border-left: 5px solid #f6ad55; color: #c05621; margin-bottom: 10px; font-size: 15px; }
    .alert-success { padding: 12px; border-radius: 8px; background-color: #f0fff4; border-left: 5px solid #48bb78; color: #2f855a; font-weight: bold; }
    div[data-testid="stMetric"] { background-color: #ffffff; border: 1px solid #e0e0e0; padding: 15px; border-radius: 10px; text-align: center; }
</style>
""", unsafe_allow_html=True)

# --- 2. H√ÄM ƒê·ªåC & X·ª¨ L√ù TEXT ---

def extract_text_from_docx(file):
    try:
        doc = Document(file)
        full_text = []
        for para in doc.paragraphs: full_text.append(para.text)
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for para in cell.paragraphs: full_text.append(para.text)
        return "\n".join(full_text)
    except: return "ERROR_DOC"

def extract_text_from_pdf(file):
    try:
        reader = PdfReader(file)
        text = ""
        for page in reader.pages: text += page.extract_text() + "\n"
        return text
    except: return "ERROR_PDF"

def preprocess_text(text):
    """
    L√†m s·∫°ch vƒÉn b·∫£n tri·ªát ƒë·ªÉ tr∆∞·ªõc khi x·ª≠ l√Ω
    """
    # 1. N·ªëi c√°c t·ª´ b·ªã ng·∫Øt d√≤ng (Rah-\n mati -> Rahmati)
    text = re.sub(r'-\s*\n\s*', '', text)
    # 2. X√≥a to√†n b·ªô d·∫•u xu·ªëng d√≤ng (bi·∫øn th√†nh 1 d√≤ng d√†i ƒë·ªÉ regex kh√¥ng b·ªã ƒë·ª©t)
    text = text.replace('\n', ' ').replace('\r', ' ')
    # 3. X√≥a kho·∫£ng tr·∫Øng th·ª´a
    text = re.sub(r'\s+', ' ', text)
    return text

def is_legal_or_standard(text):
    text_lower = text.lower()
    keywords = [
        'tcvn', 'qcvn', 'iso', 'lu·∫≠t', 'ngh·ªã ƒë·ªãnh', 'quy·∫øt ƒë·ªãnh', 'th√¥ng t∆∞', 
        'ch·ªâ th·ªã', 'qƒë-ttg', 'nd-cp', 'tt-btnmt', 'luat', 'nghi dinh', 
        'quyet dinh', 'thong tu', 'ti√™u chu·∫©n', 'quy chu·∫©n', 'ch√≠nh ph·ªß', 
        'qu·ªëc h·ªôi', 'b·ªô t√†i nguy√™n', 'b·ªô x√¢y d·ª±ng', 'b·ªô khoa h·ªçc'
    ]
    for kw in keywords:
        if kw in text_lower:
            return True
    return False

# --- 3. LOGIC FUZZY MATCHING (M·ªöI) ---

def check_citation_fuzzy(cit_name, cit_year, refs_list, threshold=85):
    """
    S·ª≠ d·ª•ng Fuzzy Logic ƒë·ªÉ so s√°nh ƒë·ªô t∆∞∆°ng ƒë·ªìng.
    threshold=85: Nghƒ©a l√† gi·ªëng nhau > 85% th√¨ coi l√† ƒê√öNG.
    """
    # N·∫øu l√† vƒÉn b·∫£n ph√°p lu·∫≠t -> B·ªè qua lu√¥n
    if is_legal_or_standard(cit_name): return True

    # L√†m s·∫°ch t√™n tr√≠ch d·∫´n (B·ªè et al, v√† nnk...)
    clean_cit = re.sub(r'(et al\.?|v√† nnk\.?|v√† c·ªông s·ª±|& cs\.?|&|and)', ' ', cit_name, flags=re.IGNORECASE).strip()
    
    for ref in refs_list:
        # ƒêi·ªÅu ki·ªán 1: NƒÉm ph·∫£i c√≥ trong d√≤ng Ref (NƒÉm l√† con s·ªë ch√≠nh x√°c, kh√¥ng fuzzy ƒë∆∞·ª£c)
        if str(cit_year) in ref:
            # ƒêi·ªÅu ki·ªán 2: So s√°nh t√™n b·∫±ng Fuzzy
            # token_set_ratio: C·ª±c m·∫°nh trong vi·ªác so s√°nh chu·ªói b·ªã ƒë·∫£o t·ª´ ho·∫∑c ch√®n t·ª´ th·ª´a.
            # VD: "Rahmati" vs "Rah-mati et al" -> Score r·∫•t cao
            score = fuzz.token_set_ratio(clean_cit, ref)
            
            if score >= threshold:
                return True
    return False

def find_citations_v8(text):
    citations = []
    # Pattern 1: (Name, Year)
    # ƒê√£ preprocess text th√†nh 1 d√≤ng n√™n regex ƒë∆°n gi·∫£n h∆°n
    for match in re.finditer(r'\(([^)]*?\d{4}[^)]*?)\)', text):
        content = match.group(1)
        for part in content.split(';'):
            part = part.strip()
            year_match = re.search(r'(\d{4})[a-z]?', part) 
            if year_match:
                year = year_match.group(1)
                # Lo·∫°i b·ªè d·∫•u : v√† , ·ªü cu·ªëi t√™n
                name_part = part[:year_match.start()].strip().rstrip(',:').strip()
                
                # B·ªô l·ªçc r√°c c∆° b·∫£n
                if len(name_part) > 1 and len(name_part) < 80 and not is_legal_or_standard(name_part):
                     # L·ªçc th√™m ng√†y th√°ng n·∫øu c√≤n s√≥t
                    if not re.search(r'(th√°ng|ng√†y|tr∆∞·ªõc|sau|h√¨nh|b·∫£ng)', name_part.lower()):
                        citations.append({"name": name_part, "year": year, "full": f"({name_part}, {year})"})

    # Pattern 2: Name (Year)
    for match in re.finditer(r'([A-Z√Ä-·ªπ][A-Za-z√Ä-·ªπ\s&.\-]{1,60}?)\s*\(\s*(\d{4})\s*\)', text):
        raw_name = match.group(1).strip()
        year = match.group(2)
        if not is_legal_or_standard(raw_name) and not re.search(r'(th√°ng|ng√†y|tr∆∞·ªõc|sau|h√¨nh|b·∫£ng)', raw_name.lower()):
             citations.append({"name": raw_name, "year": year, "full": f"{raw_name} ({year})"})

    # L·ªçc tr√πng
    unique_citations = []
    seen = set()
    for c in citations:
        key = f"{c['name']}_{c['year']}"
        if key not in seen:
            unique_citations.append(c)
            seen.add(key)
    return unique_citations

# --- 4. GIAO DI·ªÜN CH√çNH ---

with st.sidebar:
    st.markdown("<h2 style='text-align: center; color: #0d6efd;'>üß† Citation Pro (AI)</h2>", unsafe_allow_html=True)
    st.markdown("---")
    uploaded_file = st.file_uploader("üìÇ **Upload File (.docx / .pdf)**", type=['docx', 'pdf'])
    st.caption("Version 8.0 (Fuzzy Logic) | Build by Quan HUMG")

if not uploaded_file:
    st.markdown("<div style='text-align: center; padding: 50px;'>", unsafe_allow_html=True)
    st.title("C√¥ng c·ª• Ki·ªÉm tra Tr√≠ch d·∫´n (S·ª≠ d·ª•ng AI Fuzzy Logic)")
    st.markdown("### üöÄ X·ª≠ l√Ω t·ªët l·ªói xu·ªëng d√≤ng, ch√≠nh t·∫£, d·∫•u c√¢u")
    st.image("https://cdn-icons-png.flaticon.com/512/2103/2103633.png", width=120)
    st.info("üëà T·∫£i file b√°o c√°o b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu")
    st.markdown("</div>", unsafe_allow_html=True)

else:
    with st.container():
        with st.status("ƒêang ph√¢n t√≠ch...", expanded=True) as status:
            time.sleep(0.3)
            st.write("üìÑ ƒêang ƒë·ªçc file...")
            if uploaded_file.name.endswith('.docx'):
                raw_text = extract_text_from_docx(uploaded_file)
            else:
                raw_text = extract_text_from_pdf(uploaded_file)
            
            if raw_text.startswith("ERROR"):
                st.error("L·ªói ƒë·ªçc file!")
                st.stop()

            st.write("üßπ ƒêang l√†m s·∫°ch vƒÉn b·∫£n (n·ªëi t·ª´, x√≥a xu·ªëng d√≤ng)...")
            # --- B∆Ø·ªöC PREPROCESS QUAN TR·ªåNG ---
            # T√°ch ph·∫ßn Ref v√† Body tr∆∞·ªõc khi Preprocess ƒë·ªÉ tr√°nh g·ªôp l·∫´n l·ªôn
            matches = list(re.finditer(r"(t√†i li·ªáu tham kh·∫£o|references)", raw_text, re.IGNORECASE))
            if not matches:
                body_raw = raw_text
                ref_raw = raw_text
                st.toast("Kh√¥ng t√¨m th·∫•y m·ª•c References ri√™ng bi·ªát.", icon="‚ö†Ô∏è")
            else:
                split_idx = matches[-1].end()
                body_raw = raw_text[:matches[-1].start()]
                ref_raw = raw_text[split_idx:]
            
            # X·ª≠ l√Ω text sau khi ƒë√£ t√°ch v√πng
            body_text = preprocess_text(body_raw)
            # Ref text th√¨ t√°ch d√≤ng d·ª±a tr√™n quy t·∫Øc ri√™ng (VD: c√≥ nƒÉm)
            # Ho·∫∑c ƒë∆°n gi·∫£n l√† split theo enter g·ªëc, nh∆∞ng do file l·ªói n√™n ta split th√¥ng minh h∆°n
            # ·ªû ƒë√¢y ta gi·ªØ nguy√™n ref_raw ƒë·ªÉ split d√≤ng, nh∆∞ng khi so s√°nh s·∫Ω clean t·ª´ng d√≤ng
            ref_lines = [line.strip() for line in ref_raw.split('\n') if len(line.strip()) > 10 and re.search(r'\d{4}', line)]

            st.write("üß† ƒêang ch·∫°y thu·∫≠t to√°n Fuzzy Matching...")
            citations = find_citations_v8(body_text)

            # --- CHECK MISSING ---
            missing_refs = []
            for cit in citations:
                if not check_citation_fuzzy(cit['name'], cit['year'], ref_lines):
                    missing_refs.append(cit['full'])

            # --- CHECK UNUSED ---
            unused_refs = []
            for ref in ref_lines:
                if is_legal_or_standard(ref): continue
                
                # Logic ng∆∞·ª£c: L·∫•y nƒÉm ref, t√¨m c√°c cite c√πng nƒÉm, r·ªìi fuzzy match ng∆∞·ª£c l·∫°i
                ref_year_match = re.search(r'\d{4}', ref)
                if ref_year_match:
                    r_year = ref_year_match.group(0)
                    same_year_cites = [c for c in citations if c['year'] == r_year]
                    
                    is_found = False
                    if same_year_cites:
                        for c in same_year_cites:
                            # Check ng∆∞·ª£c: Li·ªáu t√™n trong Cite c√≥ kh·ªõp v·ªõi Ref n√†y kh√¥ng?
                            if check_citation_fuzzy(c['name'], c['year'], [ref]):
                                is_found = True
                                break
                    if not is_found:
                        unused_refs.append(ref)
            
            status.update(label="‚úÖ Ho√†n t·∫•t!", state="complete", expanded=False)

    # --- DASHBOARD ---
    m1, m2, m3, m4 = st.columns(4)
    with m1: st.metric("T·ªïng tr√≠ch d·∫´n", len(citations), border=True)
    with m2: st.metric("Danh m·ª•c Ref", len(ref_lines), border=True)
    with m3: st.metric("L·ªói thi·∫øu Ref", len(missing_refs), delta="-{}".format(len(missing_refs)) if missing_refs else "OK", delta_color="inverse", border=True)
    with m4: st.metric("L·ªói th·ª´a Ref", len(unused_refs), delta="-{}".format(len(unused_refs)) if unused_refs else "OK", delta_color="inverse", border=True)

    st.write("")
    tab1, tab2, tab3 = st.tabs(["üö´ THI·∫æU REF (Missing)", "‚ö†Ô∏è TH·ª™A REF (Unused)", "üìã D·ªÆ LI·ªÜU"])

    with tab1:
        if missing_refs:
            for i in missing_refs: st.markdown(f'<div class="alert-error">‚ùå <b>{i}</b></div>', unsafe_allow_html=True)
        else: st.markdown('<div class="alert-success">Tuy·ªát v·ªùi! Kh√¥ng thi·∫øu tr√≠ch d·∫´n n√†o.</div>', unsafe_allow_html=True)

    with tab2:
        if unused_refs:
            for i in unused_refs: st.markdown(f'<div class="alert-warning">‚ö†Ô∏è {i}</div>', unsafe_allow_html=True)
        else: st.markdown('<div class="alert-success">Danh m·ª•c t√†i li·ªáu chu·∫©n.</div>', unsafe_allow_html=True)

    with tab3:
        c1, c2 = st.columns(2)
        with c1: 
            st.caption("Citations found")
            st.write(citations)
        with c2: 
            st.caption("Reference Lines")
            st.write(ref_lines)
