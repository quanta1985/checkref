import streamlit as st
import re
import time
import pandas as pd
from docx import Document
from pypdf import PdfReader
from thefuzz import fuzz # ThÆ° viá»‡n AI

# --- 1. Cáº¤U HÃŒNH & CSS (GIá»® NGUYÃŠN 100%) ---
st.set_page_config(
    page_title="Citation Pro | AI Fuzzy Logic",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    /* Font vÃ  mÃ u ná»n tá»•ng thá»ƒ */
    .stApp { background-color: #f8f9fa; }
    
    /* Style cho cÃ¡c Card (Khá»‘i) */
    .css-card {
        border-radius: 15px; padding: 20px; background-color: white;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05); margin-bottom: 20px; border: 1px solid #e9ecef;
    }
    
    /* Header chÃ­nh */
    .main-header { font-family: 'Helvetica Neue', sans-serif; color: #0d6efd; text-align: center; margin-bottom: 30px; }
    
    /* Metric Box */
    div[data-testid="stMetric"] {
        background-color: #ffffff; border: 1px solid #e0e0e0; padding: 15px;
        border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); text-align: center;
    }
    
    /* Alert Boxes */
    .alert-error { padding: 12px; border-radius: 8px; background-color: #fff5f5; border-left: 5px solid #fc8181; color: #c53030; margin-bottom: 10px; font-size: 15px; }
    .alert-warning { padding: 12px; border-radius: 8px; background-color: #fffaf0; border-left: 5px solid #f6ad55; color: #c05621; margin-bottom: 10px; font-size: 15px; }
    .alert-success { padding: 12px; border-radius: 8px; background-color: #f0fff4; border-left: 5px solid #48bb78; color: #2f855a; font-weight: bold; }
    .beta-note { font-size: 13px; color: #6c757d; font-style: italic; text-align: center; margin-bottom: 20px; }
</style>
""", unsafe_allow_html=True)

# --- 2. CÃC HÃ€M Xá»¬ LÃ (LOGIC v12.2 - Data Cleaner) ---

def extract_text_from_docx(file):
    try:
        doc = Document(file)
        full_text = []
        for para in doc.paragraphs: full_text.append(para.text)
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for para in cell.paragraphs: full_text.append(para.text)
        return "\n".join(full_text)
    except: return "ERROR_DOC"

def extract_text_from_pdf(file):
    try:
        reader = PdfReader(file)
        text = ""
        for page in reader.pages: text += page.extract_text() + "\n"
        return text
    except: return "ERROR_PDF"

def preprocess_text(text):
    text = re.sub(r'-\s*\n\s*', '', text)
    text = text.replace('\n', ' ').replace('\r', ' ')
    text = re.sub(r'\s+', ' ', text)
    return text

def is_legal_or_standard(text):
    text_lower = text.lower()
    keywords = [
        'tcvn', 'qcvn', 'iso', 'luáº­t', 'nghá»‹ Ä‘á»‹nh', 'quyáº¿t Ä‘á»‹nh', 'thÃ´ng tÆ°', 
        'chá»‰ thá»‹', 'qÄ‘-ttg', 'nd-cp', 'tt-btnmt', 'luat', 'nghi dinh', 
        'quyet dinh', 'thong tu', 'tiÃªu chuáº©n', 'quy chuáº©n', 'chÃ­nh phá»§', 
        'quá»‘c há»™i', 'bá»™ tÃ i nguyÃªn', 'bá»™ xÃ¢y dá»±ng', 'bá»™ khoa há»c', 'bá»™ tnmt'
    ]
    for kw in keywords:
        if kw in text_lower: return True
    return False

def is_garbage(text):
    text_lower = text.lower()
    # Cáº­p nháº­t danh sÃ¡ch tá»« khÃ³a rÃ¡c (data keywords)
    blacklist = [
        'thÃ¡ng', 'ngÃ y', 'nÄƒm', 'lÃºc', 'trÆ°á»›c', 'sau', 'khoáº£ng', 'hÃ¬nh', 'báº£ng', 'biá»ƒu', 
        'sÆ¡ Ä‘á»“', 'phÆ°Æ¡ng trÃ¬nh', 'cÃ´ng thá»©c', 'há»‡ sá»‘', 'giÃ¡ trá»‹', 'tá»‰ lá»‡', 'káº¿t quáº£', 
        'Ä‘oáº¡n', 'pháº§n', 'má»¥c', 'báº£n Ä‘á»“', 'giai Ä‘oáº¡n', 'sá»‘', 'nghiÃªn cá»©u', 'phÃ¢n tÃ­ch', 
        'Ä‘Ã¡nh giÃ¡', 'Ä‘á»‘i vá»›i', 'cá»§a', 'bá»Ÿi', 'Ä‘Æ°á»£c', 'trong', 'táº¡i', 
        'tÆ°Æ¡ng Ä‘Æ°Æ¡ng', 'tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i', 'dao Ä‘á»™ng', 'Ä‘áº¿n', 'tá»«' # <--- ThÃªm tá»« khÃ³a má»›i
    ]
    for word in blacklist:
        if re.search(r'\b' + re.escape(word) + r'\b', text_lower):
            return True
    
    invalid_chars = ['/', '=', '>', '<', '%', '+', '\\']
    for char in invalid_chars:
        if char in text: return True
        
    return False

def expand_abbreviation(name):
    abbr_dict = {
        'Bá»˜ TNMT': 'Bá»˜ TÃ€I NGUYÃŠN VÃ€ MÃ”I TRÆ¯á»œNG',
        'Bá»˜ TN&MT': 'Bá»˜ TÃ€I NGUYÃŠN VÃ€ MÃ”I TRÆ¯á»œNG',
        'BTNMT': 'Bá»˜ TÃ€I NGUYÃŠN VÃ€ MÃ”I TRÆ¯á»œNG',
        'Bá»˜ KHCN': 'Bá»˜ KHOA Há»ŒC VÃ€ CÃ”NG NGHá»†',
        'Bá»˜ NNPTNT': 'Bá»˜ NÃ”NG NGHIá»†P VÃ€ PHÃT TRIá»‚N NÃ”NG THÃ”N',
        'Bá»˜ XD': 'Bá»˜ XÃ‚Y Dá»°NG',
        'UBND': 'á»¦Y BAN NHÃ‚N DÃ‚N',
        'CP': 'CHÃNH PHá»¦',
        'QH': 'QUá»C Há»˜I'
    }
    
    name_upper = name.upper()
    for abbr, full in abbr_dict.items():
        if abbr in name_upper:
            return name_upper.replace(abbr, full)
    return name

def check_citation_fuzzy(cit_name, cit_year, refs_list, threshold=65):
    if is_legal_or_standard(cit_name): return True

    clean_cit = re.sub(r'(et\s*al\.?|vÃ \s*nnk\.?|vÃ \s*cá»™ng\s*sá»±|vÃ \s*cs\.?|&\s*cs\.?|&|and)', ' ', cit_name, flags=re.IGNORECASE).strip()
    clean_cit = re.sub(r'^(Ä‘Æ°á»£c|bá»Ÿi|cá»§a|theo)\s+', '', clean_cit, flags=re.IGNORECASE).strip()
    
    expanded_cit = expand_abbreviation(clean_cit)

    for ref in refs_list:
        if str(cit_year) in ref:
            # 1. Prefix Check
            clean_ref_start = re.sub(r'^\s*(\[?\d+\]?\.?)\s+', '', ref, count=1)
            if clean_ref_start.lower().startswith(clean_cit.lower()):
                return True
            
            # 2. Author Isolation
            match_year = re.search(str(cit_year), ref)
            if match_year:
                author_part_only = ref[:match_year.start()]
                score_author = fuzz.token_set_ratio(clean_cit, author_part_only)
                if score_author >= threshold: return True

            # 3. Full String Backup
            score1 = fuzz.token_set_ratio(clean_cit, ref)
            score2 = 0
            if expanded_cit != clean_cit:
                score2 = fuzz.token_set_ratio(expanded_cit, ref)
            
            if max(score1, score2) >= threshold:
                return True
    return False

def find_citations_v12(text):
    citations = []
    
    # Pattern 1: Trong ngoáº·c (...)
    for match in re.finditer(r'\(([^)]*?\d{4}[^)]*?)\)', text):
        content = match.group(1)
        for part in content.split(';'):
            part = part.strip()
            year_match = re.search(r'(\d{4})[a-z]?', part) 
            if year_match:
                year = year_match.group(1)
                name_part = part[:year_match.start()].strip().rstrip(',:').strip()
                
                # === NEW FIX v12.2: TÃªn tÃ¡c giáº£ KHÃ”NG ÄÆ¯á»¢C chá»©a sá»‘ ===
                # Náº¿u name_part chá»©a báº¥t ká»³ chá»¯ sá»‘ nÃ o (0-9) -> Skip ngay láº­p tá»©c
                # VD: "tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 560,79" -> CÃ³ sá»‘ -> Loáº¡i
                if re.search(r'\d', name_part):
                    continue
                # ====================================================

                if len(name_part) > 1 and len(name_part) < 100 and not is_legal_or_standard(name_part):
                     if not is_garbage(name_part):
                        citations.append({"name": name_part, "year": year, "full": f"({name_part}, {year})"})

    # Pattern 2: Dáº¡ng má»Ÿ Name (Year)
    for match in re.finditer(r'([A-ZÃ€-á»¹][A-Za-zÃ€-á»¹\s&\-,]{1,60}?)\s*\(\s*(\d{4})\s*\)', text):
        raw_name = match.group(1).strip()
        year = match.group(2)
        
        # Ãp dá»¥ng logic tÆ°Æ¡ng tá»±: TÃªn khÃ´ng Ä‘Æ°á»£c chá»©a sá»‘
        if re.search(r'\d', raw_name): continue

        if not is_legal_or_standard(raw_name) and not is_garbage(raw_name):
             citations.append({"name": raw_name, "year": year, "full": f"{raw_name} ({year})"})

    unique_citations = []
    seen = set()
    for c in citations:
        key = f"{c['name']}_{c['year']}"
        if key not in seen:
            unique_citations.append(c)
            seen.add(key)
    return unique_citations

# --- 3. GIAO DIá»†N CHÃNH (GIá»® NGUYÃŠN) ---

# --- SIDEBAR ---
with st.sidebar:
    st.markdown("<h2 style='text-align: center; color: #0d6efd;'>ğŸ“ Citation Pro <br><span style='font-size:16px; color: #666;'>(AI FUZZY CHECK)</span></h2>", unsafe_allow_html=True)
    st.markdown("---")
    uploaded_file = st.file_uploader("ğŸ“‚ **Táº£i bÃ¡o cÃ¡o lÃªn Ä‘Ã¢y**:", type=['docx', 'pdf'])
    
    st.markdown("---")
    with st.expander("â„¹ï¸ HÆ°á»›ng dáº«n sá»­ dá»¥ng"):
        st.markdown("""
        1. Upload file bÃ¡o cÃ¡o (.docx/.pdf).
        2. Chá» há»‡ thá»‘ng tá»± Ä‘á»™ng quÃ©t.
        3. Xem káº¿t quáº£ táº¡i Dashboard bÃªn pháº£i.
        """)
    
    st.info("âš ï¸ **LÆ°u Ã½:** App Ä‘ang trong quÃ¡ trÃ¬nh phÃ¡t triá»ƒn (Beta). Káº¿t quáº£ kiá»ƒm tra chá»‰ mang tÃ­nh cháº¥t tham kháº£o nhanh.")
    st.caption("Dev by Quan HUMG")

# --- MAIN PAGE ---
if not uploaded_file:
    st.markdown("<div style='text-align: center; padding: 50px;'>", unsafe_allow_html=True)
    st.title("CÃ´ng cá»¥ RÃ  soÃ¡t TrÃ­ch dáº«n & TÃ i liá»‡u tham kháº£o")
    st.markdown("### ğŸš€ Nhanh chÃ³ng - (Gáº§n) ChÃ­nh xÃ¡c - (Sáº¯p) ChuyÃªn nghiá»‡p - VÃ  JUST FOR FUN ğŸ˜")
    st.markdown("Kiá»ƒm tra sá»± Ä‘á»“ng bá»™ giá»¯a *TrÃ­ch dáº«n trong bÃ i (In-text)* vÃ  *Danh má»¥c tham kháº£o (References)*.")
    st.image("https://cdn-icons-png.flaticon.com/512/8662/8662266.png", width=150)
    st.info("ğŸ‘ˆ Vui lÃ²ng táº£i file bÃ¡o cÃ¡o á»Ÿ thanh bÃªn trÃ¡i Ä‘á»ƒ báº¯t Ä‘áº§u.")
    st.markdown("</div>", unsafe_allow_html=True)

else:
    # --- Xá»¬ LÃ Dá»® LIá»†U ---
    with st.container():
        with st.status("Äang phÃ¢n tÃ­ch dá»¯ liá»‡u...", expanded=True) as status:
            time.sleep(0.3)
            st.write("ğŸ“„ Äang Ä‘á»c vÃ  lÃ m sáº¡ch file...")
            
            if uploaded_file.name.endswith('.docx'):
                raw_text = extract_text_from_docx(uploaded_file)
            else:
                raw_text = extract_text_from_pdf(uploaded_file)
            
            if raw_text.startswith("ERROR"):
                status.update(label="âŒ Lá»—i Ä‘á»c file!", state="error")
                st.stop()

            st.write("ğŸ” Äang tÃ¡ch danh má»¥c vÃ  trÃ­ch dáº«n...")
            matches = list(re.finditer(r"(tÃ i liá»‡u tham kháº£o|references)", raw_text, re.IGNORECASE))
            if not matches:
                ref_raw = raw_text
                body_raw = raw_text
                st.toast("âš ï¸ KhÃ´ng tÃ¬m tháº¥y tiÃªu Ä‘á» References, quÃ©t toÃ n bá»™.", icon="âš ï¸")
            else:
                split_idx = matches[-1].end()
                body_raw = raw_text[:matches[-1].start()]
                ref_raw = raw_text[split_idx:]
            
            body_text = preprocess_text(body_raw)
            ref_lines = [line.strip() for line in ref_raw.split('\n') if len(line.strip()) > 10 and re.search(r'\d{4}', line)]

            st.write("ğŸ§  Äang cháº¡y thuáº­t toÃ¡n AI Fuzzy Matching...")
            citations = find_citations_v12(body_text)

            # --- LOGIC CHECK (FUZZY) ---
            missing_refs = []
            for cit in citations:
                if not check_citation_fuzzy(cit['name'], cit['year'], ref_lines):
                    missing_refs.append(cit['full'])

            unused_refs = []
            for ref in ref_lines:
                if is_legal_or_standard(ref): continue
                
                ref_year_match = re.search(r'\d{4}', ref)
                if ref_year_match:
                    r_year = ref_year_match.group(0)
                    same_year_cites = [c for c in citations if c['year'] == r_year]
                    
                    is_found = False
                    if same_year_cites:
                        for c in same_year_cites:
                            if check_citation_fuzzy(c['name'], c['year'], [ref]):
                                is_found = True
                                break
                    if not is_found:
                        unused_refs.append(ref)
            
            status.update(label="âœ… ÄÃ£ phÃ¢n tÃ­ch xong!", state="complete", expanded=False)

    # --- DASHBOARD Káº¾T QUáº¢ ---
    
    st.markdown("<h3 style='margin-top: 20px;'>ğŸ“Š Tá»•ng quan (Dashboard)</h3>", unsafe_allow_html=True)
    
    st.markdown("""
    <div style="background-color: #ffe6e6; border: 1px solid #ffcccc; padding: 10px; border-radius: 5px; color: #cc0000; margin-bottom: 15px; font-size: 14px;">
        <b>âš ï¸ LÆ¯U Ã:</b> Nhá»¯ng trÃ­ch dáº«n bá»‹ xuá»‘ng dÃ²ng trong báº£n tháº£o (vÃ­ dá»¥ <i>Rasmussen</i> thÃ nh <i>Ras-mussen</i>) cÃ³ thá»ƒ bá»‹ bÃ¡o lá»—i thiáº¿u trÃ­ch dáº«n do háº¡n cháº¿ cá»§a viá»‡c trÃ­ch xuáº¥t vÄƒn báº£n PDF. Vui lÃ²ng kiá»ƒm tra láº¡i thá»§ cÃ´ng.
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('<p class="beta-note">(*) Káº¿t quáº£ dá»±a trÃªn AI Fuzzy Logic. Vui lÃ²ng kiá»ƒm tra láº¡i thá»§ cÃ´ng cÃ¡c má»¥c bÃ¡o lá»—i.</p>', unsafe_allow_html=True)
    
    # Metrics
    m1, m2, m3, m4 = st.columns(4)
    with m1: st.metric("Tá»•ng trÃ­ch dáº«n", len(citations), border=True)
    with m2: st.metric("Danh má»¥c Ref", len(ref_lines), border=True)
    
    err_missing = len(missing_refs)
    err_unused = len(unused_refs)
    
    with m3: 
        st.metric("Lá»—i thiáº¿u Ref", err_missing, delta="-{}".format(err_missing) if err_missing > 0 else "OK", delta_color="inverse", border=True)
    with m4:
        st.metric("Lá»—i thá»«a Ref", err_unused, delta="-{}".format(err_unused) if err_unused > 0 else "OK", delta_color="inverse", border=True)

    st.write("") 

    # Tabs
    tab_miss, tab_unused, tab_data = st.tabs(["ğŸš« TRÃCH DáºªN THIáº¾U (Missing)", "âš ï¸ DANH Má»¤C THá»ªA (Unused)", "ğŸ“‹ Dá»® LIá»†U CHI TIáº¾T"])

    with tab_miss:
        st.markdown(f"**Danh sÃ¡ch {len(missing_refs)} trÃ­ch dáº«n cÃ³ trong bÃ i nhÆ°ng khÃ´ng tÃ¬m tháº¥y trong danh má»¥c:**")
        if missing_refs:
            for item in missing_refs:
                st.markdown(f'<div class="alert-error">âŒ <b>{item}</b> - <i>KhÃ´ng tÃ¬m tháº¥y nguá»“n</i></div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="alert-success">ğŸ‰ Tuyá»‡t vá»i! KhÃ´ng cÃ³ trÃ­ch dáº«n nÃ o bá»‹ thiáº¿u.</div>', unsafe_allow_html=True)

    with tab_unused:
        st.markdown(f"**Danh sÃ¡ch {len(unused_refs)} tÃ i liá»‡u cÃ³ trong danh má»¥c nhÆ°ng chÆ°a Ä‘Æ°á»£c trÃ­ch dáº«n:**")
        if unused_refs:
            for item in unused_refs:
                st.markdown(f'<div class="alert-warning">âš ï¸ {item}</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="alert-success">ğŸ‰ Danh má»¥c tÃ i liá»‡u ráº¥t gá»n gÃ ng.</div>', unsafe_allow_html=True)

    with tab_data:
        st.markdown("#### Tra cá»©u dá»¯ liá»‡u gá»‘c")
        col_d1, col_d2 = st.columns(2)
        
        with col_d1:
            st.caption("Dá»¯ liá»‡u TrÃ­ch dáº«n (In-text)")
            if citations:
                df_cit = pd.DataFrame(citations)
                st.dataframe(df_cit, use_container_width=True, hide_index=True)
            else: st.info("KhÃ´ng cÃ³ dá»¯ liá»‡u")

        with col_d2:
            st.caption("Dá»¯ liá»‡u Danh má»¥c (References)")
            if ref_lines:
                df_ref = pd.DataFrame(ref_lines, columns=["Ná»™i dung tham kháº£o"])
                st.dataframe(df_ref, use_container_width=True, hide_index=True)
            else: st.info("KhÃ´ng cÃ³ dá»¯ liá»‡u")
